{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Homework-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1dv_kB7nO6Lj1xkK0siaq0He-QFpR-xb6",
      "authorship_tag": "ABX9TyPENUWAzrBwUtARlqvFqg1M",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tirth-pandya/MultiModalClassifier/blob/main/Homework_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka9bIyoaI6Q7"
      },
      "source": [
        "!git clone https://github.com/lkk688/MultiModalClassifier.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tc9qWWMaKzXb",
        "outputId": "919e81eb-85aa-40f2-c3a7-bb2bee810033"
      },
      "source": [
        "!pip install configargparse"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting configargparse\n",
            "  Downloading ConfigArgParse-1.5.3-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: configargparse\n",
            "Successfully installed configargparse-1.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHJ7-e5OPPKO",
        "outputId": "8402e885-7f4a-4858-dcb8-2445cc00c386"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwrjKsI3SR2O",
        "outputId": "a287a027-8047-4a44-a870-f104d83cbe1c"
      },
      "source": [
        "%cd /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/\n",
        "!python ./setup.py develop"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ColabNotebooks/MultiModalClassifier\n",
            "running develop\n",
            "running egg_info\n",
            "writing MultimodalClassifier.egg-info/PKG-INFO\n",
            "writing dependency_links to MultimodalClassifier.egg-info/dependency_links.txt\n",
            "writing requirements to MultimodalClassifier.egg-info/requires.txt\n",
            "writing top-level names to MultimodalClassifier.egg-info/top_level.txt\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'MultimodalClassifier.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.7/dist-packages/MultimodalClassifier.egg-link (link to .)\n",
            "Adding MultimodalClassifier 0.0.1 to easy-install.pth file\n",
            "\n",
            "Installed /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier\n",
            "Processing dependencies for MultimodalClassifier==0.0.1\n",
            "Searching for numpy==1.19.5\n",
            "Best match: numpy 1.19.5\n",
            "Adding numpy 1.19.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for MultimodalClassifier==0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGHykgyhS6Lq"
      },
      "source": [
        "!python /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/TorchClassifier/Datasetutil/Torchdatasetutil.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeK4XILPVRWQ",
        "outputId": "0a5049af-af55-404e-add2-87f8967b3185"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Sep 30 20:11:24 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD9GbXqDViYV",
        "outputId": "a95bfff1-ee68-49d6-a969-4f209e97e591"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y76oKFxmV7rS",
        "outputId": "e9ef5673-e7f6-40a4-82cd-73dae9c70674"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"TF Version : \", tf.version.VERSION)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Version :  2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Gi_5mN0X8_L",
        "outputId": "64091035-bddf-4031-ccd6-f21f43e59c03"
      },
      "source": [
        "!python /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/TorchClassifier/myTorchTrainer.py --TAG scenario_1 --model_name alexnet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.9.0+cu102\n",
            "Torch Version:  1.9.0+cu102\n",
            "Torchvision Version:  0.10.0+cu102\n",
            "Output path: ./outputs/CIFAR10_alexnet_scenario_1\n",
            "Num GPUs: 1\n",
            "0\n",
            "Tesla K80\n",
            "True\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Number of training examples: 50000\n",
            "Number of testing examples: 10000\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "trainable parameters: 1728\n",
            "trainable parameters: 64\n",
            "trainable parameters: 110592\n",
            "trainable parameters: 192\n",
            "trainable parameters: 663552\n",
            "trainable parameters: 384\n",
            "trainable parameters: 884736\n",
            "trainable parameters: 256\n",
            "trainable parameters: 589824\n",
            "trainable parameters: 256\n",
            "trainable parameters: 4194304\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 16777216\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 40960\n",
            "trainable parameters: 10\n",
            "The model has 23272266 trainable parameters\n",
            " *************  1250\n",
            "Epoch 0/14\n",
            "----------\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/TorchClassifier/myTorchTrainer.py\", line 253, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/TorchClassifier/myTorchTrainer.py\", line 240, in main\n",
            "    num_epochs=args.epochs)\n",
            "  File \"/content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/TorchClassifier/myTorchTrainer.py\", line 125, in train_model\n",
            "    running_loss += loss.item() * inputs.size(0)#batch size\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSdX6rwFoOKf",
        "outputId": "6ecf5155-7dec-4036-bbb9-406e05b4620d"
      },
      "source": [
        "!python /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/TorchClassifier/myTorchEvaluator.py --save_path /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/outputs/ --TAG scenario_1 --model_name alexnet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.9.0+cu102\n",
            "Torch Version:  1.9.0+cu102\n",
            "Torchvision Version:  0.10.0+cu102\n",
            "Output path: /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/outputs/CIFAR10_alexnet_scenario_1\n",
            "Num GPUs: 1\n",
            "0\n",
            "Tesla K80\n",
            "True\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Number of training examples: 50000\n",
            "Number of testing examples: 10000\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "trainable parameters: 1728\n",
            "trainable parameters: 64\n",
            "trainable parameters: 110592\n",
            "trainable parameters: 192\n",
            "trainable parameters: 663552\n",
            "trainable parameters: 384\n",
            "trainable parameters: 884736\n",
            "trainable parameters: 256\n",
            "trainable parameters: 589824\n",
            "trainable parameters: 256\n",
            "trainable parameters: 4194304\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 16777216\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 40960\n",
            "trainable parameters: 10\n",
            "The model has 23272266 trainable parameters\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Test Loss: 0.941671\n",
            "\n",
            "Test Accuracy of airplane: 75% (759/1000)\n",
            "Test Accuracy of automobile: 84% (843/1000)\n",
            "Test Accuracy of  bird: 58% (588/1000)\n",
            "Test Accuracy of   cat: 51% (510/1000)\n",
            "Test Accuracy of  deer: 63% (634/1000)\n",
            "Test Accuracy of   dog: 50% (503/1000)\n",
            "Test Accuracy of  frog: 77% (777/1000)\n",
            "Test Accuracy of horse: 74% (741/1000)\n",
            "Test Accuracy of  ship: 83% (832/1000)\n",
            "Test Accuracy of truck: 77% (777/1000)\n",
            "\n",
            "Test Accuracy (Overall): 69% (6964/10000)\n",
            "Test Loss: 0.941 | Test Acc: 69.66%\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMJlHh5UzS1Q",
        "outputId": "06f33478-9260-45ad-dba3-28b9879f2dc0"
      },
      "source": [
        "!python /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/TorchClassifier/myTorchTrainer.py --TAG scenario_2 --model_name alexnet --optimizer SGD --epochs 25"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.9.0+cu102\n",
            "Torch Version:  1.9.0+cu102\n",
            "Torchvision Version:  0.10.0+cu102\n",
            "Output path: ./outputs/CIFAR10_alexnet_scenario_2\n",
            "Num GPUs: 1\n",
            "0\n",
            "Tesla K80\n",
            "True\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Number of training examples: 50000\n",
            "Number of testing examples: 10000\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "trainable parameters: 1728\n",
            "trainable parameters: 64\n",
            "trainable parameters: 110592\n",
            "trainable parameters: 192\n",
            "trainable parameters: 663552\n",
            "trainable parameters: 384\n",
            "trainable parameters: 884736\n",
            "trainable parameters: 256\n",
            "trainable parameters: 589824\n",
            "trainable parameters: 256\n",
            "trainable parameters: 4194304\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 16777216\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 40960\n",
            "trainable parameters: 10\n",
            "The model has 23272266 trainable parameters\n",
            " *************  1250\n",
            "Epoch 0/24\n",
            "----------\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "train Loss: 2.3024 Acc: 0.1032\n",
            "val Loss: 2.3020 Acc: 0.0945\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 2.3008 Acc: 0.1108\n",
            "val Loss: 2.2972 Acc: 0.1102\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 2.2318 Acc: 0.1548\n",
            "val Loss: 2.0410 Acc: 0.2067\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 1.9414 Acc: 0.2319\n",
            "val Loss: 1.8711 Acc: 0.2552\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 1.8154 Acc: 0.2843\n",
            "val Loss: 1.7671 Acc: 0.3095\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 1.7077 Acc: 0.3422\n",
            "val Loss: 1.6758 Acc: 0.3435\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 1.6011 Acc: 0.3906\n",
            "val Loss: 1.6095 Acc: 0.3959\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 1.4835 Acc: 0.4403\n",
            "val Loss: 1.4589 Acc: 0.4453\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 1.4608 Acc: 0.4480\n",
            "val Loss: 1.4482 Acc: 0.4498\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 1.4443 Acc: 0.4519\n",
            "val Loss: 1.4318 Acc: 0.4582\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 1.4307 Acc: 0.4580\n",
            "val Loss: 1.4379 Acc: 0.4587\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 1.4136 Acc: 0.4665\n",
            "val Loss: 1.3968 Acc: 0.4708\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 1.3989 Acc: 0.4732\n",
            "val Loss: 1.3964 Acc: 0.4746\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 1.3847 Acc: 0.4773\n",
            "val Loss: 1.3750 Acc: 0.4804\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 1.3687 Acc: 0.4821\n",
            "val Loss: 1.3716 Acc: 0.4821\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 1.3637 Acc: 0.4853\n",
            "val Loss: 1.3632 Acc: 0.4879\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 1.3621 Acc: 0.4847\n",
            "val Loss: 1.3649 Acc: 0.4844\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 1.3611 Acc: 0.4865\n",
            "val Loss: 1.3684 Acc: 0.4834\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 1.3598 Acc: 0.4850\n",
            "val Loss: 1.3576 Acc: 0.4888\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 1.3559 Acc: 0.4884\n",
            "val Loss: 1.3646 Acc: 0.4852\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 1.3552 Acc: 0.4874\n",
            "val Loss: 1.3592 Acc: 0.4872\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 1.3529 Acc: 0.4899\n",
            "val Loss: 1.3580 Acc: 0.4883\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 1.3545 Acc: 0.4904\n",
            "val Loss: 1.3598 Acc: 0.4882\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 1.3521 Acc: 0.4891\n",
            "val Loss: 1.3589 Acc: 0.4878\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 1.3533 Acc: 0.4890\n",
            "val Loss: 1.3591 Acc: 0.4886\n",
            "\n",
            "Training complete in 23m 19s\n",
            "Best val Acc: 0.488800\n",
            "<Figure size 2500x400 with 20 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX75ZsQG9l7X",
        "outputId": "56717b9a-6df0-4c1f-e669-355f5d48514d"
      },
      "source": [
        "!python /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/TorchClassifier/myTorchEvaluator.py --save_path /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/outputs/ --TAG scenario_2 --model_name alexnet --optimizer SGD --epochs 25"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.9.0+cu102\n",
            "Torch Version:  1.9.0+cu102\n",
            "Torchvision Version:  0.10.0+cu102\n",
            "Output path: /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/outputs/CIFAR10_alexnet_scenario_2\n",
            "Num GPUs: 1\n",
            "0\n",
            "Tesla K80\n",
            "True\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Number of training examples: 50000\n",
            "Number of testing examples: 10000\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "trainable parameters: 1728\n",
            "trainable parameters: 64\n",
            "trainable parameters: 110592\n",
            "trainable parameters: 192\n",
            "trainable parameters: 663552\n",
            "trainable parameters: 384\n",
            "trainable parameters: 884736\n",
            "trainable parameters: 256\n",
            "trainable parameters: 589824\n",
            "trainable parameters: 256\n",
            "trainable parameters: 4194304\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 16777216\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 40960\n",
            "trainable parameters: 10\n",
            "The model has 23272266 trainable parameters\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Test Loss: 1.353104\n",
            "\n",
            "Test Accuracy of airplane: 50% (506/1000)\n",
            "Test Accuracy of automobile: 64% (647/1000)\n",
            "Test Accuracy of  bird: 25% (253/1000)\n",
            "Test Accuracy of   cat: 28% (286/1000)\n",
            "Test Accuracy of  deer: 28% (283/1000)\n",
            "Test Accuracy of   dog: 51% (518/1000)\n",
            "Test Accuracy of  frog: 63% (634/1000)\n",
            "Test Accuracy of horse: 61% (614/1000)\n",
            "Test Accuracy of  ship: 69% (690/1000)\n",
            "Test Accuracy of truck: 44% (445/1000)\n",
            "\n",
            "Test Accuracy (Overall): 48% (4876/10000)\n",
            "Test Loss: 1.353 | Test Acc: 48.77%\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SlySTaP-cil",
        "outputId": "aa3652a4-2e86-42ec-c63e-2d335e4cf8f6"
      },
      "source": [
        "!python /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/TorchClassifier/myTorchTrainer.py --TAG scenario_2 --model_name alexnet --optimizer Adam  --epochs 25"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.9.0+cu102\n",
            "Torch Version:  1.9.0+cu102\n",
            "Torchvision Version:  0.10.0+cu102\n",
            "Output path: ./outputs/CIFAR10_alexnet_scenario_2\n",
            "Num GPUs: 1\n",
            "0\n",
            "Tesla K80\n",
            "True\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Number of training examples: 50000\n",
            "Number of testing examples: 10000\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "trainable parameters: 1728\n",
            "trainable parameters: 64\n",
            "trainable parameters: 110592\n",
            "trainable parameters: 192\n",
            "trainable parameters: 663552\n",
            "trainable parameters: 384\n",
            "trainable parameters: 884736\n",
            "trainable parameters: 256\n",
            "trainable parameters: 589824\n",
            "trainable parameters: 256\n",
            "trainable parameters: 4194304\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 16777216\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 40960\n",
            "trainable parameters: 10\n",
            "The model has 23272266 trainable parameters\n",
            " *************  1250\n",
            "Epoch 0/24\n",
            "----------\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "train Loss: 1.7286 Acc: 0.3341\n",
            "val Loss: 1.3925 Acc: 0.4828\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 1.3340 Acc: 0.5202\n",
            "val Loss: 1.2289 Acc: 0.5561\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 1.1580 Acc: 0.5915\n",
            "val Loss: 1.1826 Acc: 0.5801\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 1.0528 Acc: 0.6322\n",
            "val Loss: 1.0820 Acc: 0.6344\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.9614 Acc: 0.6682\n",
            "val Loss: 1.0408 Acc: 0.6501\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.8815 Acc: 0.6974\n",
            "val Loss: 0.9842 Acc: 0.6572\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.8169 Acc: 0.7187\n",
            "val Loss: 1.0044 Acc: 0.6560\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.5958 Acc: 0.7936\n",
            "val Loss: 0.9054 Acc: 0.7023\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.5234 Acc: 0.8171\n",
            "val Loss: 0.9274 Acc: 0.7058\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.4808 Acc: 0.8325\n",
            "val Loss: 0.9732 Acc: 0.7051\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.4413 Acc: 0.8447\n",
            "val Loss: 0.9896 Acc: 0.7067\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.4040 Acc: 0.8601\n",
            "val Loss: 1.0476 Acc: 0.7046\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.3680 Acc: 0.8717\n",
            "val Loss: 1.0891 Acc: 0.7055\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.3383 Acc: 0.8821\n",
            "val Loss: 1.1469 Acc: 0.7051\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.2918 Acc: 0.9000\n",
            "val Loss: 1.1809 Acc: 0.7071\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.2811 Acc: 0.9044\n",
            "val Loss: 1.2051 Acc: 0.7067\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.2764 Acc: 0.9061\n",
            "val Loss: 1.2333 Acc: 0.7060\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.2721 Acc: 0.9058\n",
            "val Loss: 1.2503 Acc: 0.7062\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.2682 Acc: 0.9079\n",
            "val Loss: 1.2599 Acc: 0.7058\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.2626 Acc: 0.9092\n",
            "val Loss: 1.2781 Acc: 0.7065\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.2573 Acc: 0.9114\n",
            "val Loss: 1.2982 Acc: 0.7047\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.2507 Acc: 0.9149\n",
            "val Loss: 1.2993 Acc: 0.7061\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.2535 Acc: 0.9128\n",
            "val Loss: 1.3001 Acc: 0.7062\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.2504 Acc: 0.9150\n",
            "val Loss: 1.3022 Acc: 0.7065\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.2528 Acc: 0.9145\n",
            "val Loss: 1.3032 Acc: 0.7052\n",
            "\n",
            "Training complete in 27m 29s\n",
            "Best val Acc: 0.707100\n",
            "<Figure size 2500x400 with 20 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvWVEpMOg14U",
        "outputId": "792e2414-bb77-416e-9c1e-d28a9192444f"
      },
      "source": [
        "!python /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/TorchClassifier/myTorchEvaluator.py --save_path /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/outputs/ --TAG scenario_2 --model_name alexnet --optimizer Adam --epochs 25"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.9.0+cu102\n",
            "Torch Version:  1.9.0+cu102\n",
            "Torchvision Version:  0.10.0+cu102\n",
            "Output path: /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/outputs/CIFAR10_alexnet_scenario_2\n",
            "Num GPUs: 1\n",
            "0\n",
            "Tesla K80\n",
            "True\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Number of training examples: 50000\n",
            "Number of testing examples: 10000\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "trainable parameters: 1728\n",
            "trainable parameters: 64\n",
            "trainable parameters: 110592\n",
            "trainable parameters: 192\n",
            "trainable parameters: 663552\n",
            "trainable parameters: 384\n",
            "trainable parameters: 884736\n",
            "trainable parameters: 256\n",
            "trainable parameters: 589824\n",
            "trainable parameters: 256\n",
            "trainable parameters: 4194304\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 16777216\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 40960\n",
            "trainable parameters: 10\n",
            "The model has 23272266 trainable parameters\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Test Loss: 1.236265\n",
            "\n",
            "Test Accuracy of airplane: 76% (767/1000)\n",
            "Test Accuracy of automobile: 82% (825/1000)\n",
            "Test Accuracy of  bird: 59% (597/1000)\n",
            "Test Accuracy of   cat: 54% (541/1000)\n",
            "Test Accuracy of  deer: 63% (634/1000)\n",
            "Test Accuracy of   dog: 53% (531/1000)\n",
            "Test Accuracy of  frog: 78% (784/1000)\n",
            "Test Accuracy of horse: 72% (723/1000)\n",
            "Test Accuracy of  ship: 81% (818/1000)\n",
            "Test Accuracy of truck: 77% (778/1000)\n",
            "\n",
            "Test Accuracy (Overall): 69% (6998/10000)\n",
            "Test Loss: 1.237 | Test Acc: 69.99%\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfLlW9tqha2i",
        "outputId": "b0186e4f-b4a4-43ac-d734-ef8a8489b1c7"
      },
      "source": [
        "!python /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/TorchClassifier/myTorchTrainer.py --TAG scenario_3 --model_name alexnet --optimizer Adam  --epochs 35"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.9.0+cu102\n",
            "Torch Version:  1.9.0+cu102\n",
            "Torchvision Version:  0.10.0+cu102\n",
            "Output path: ./outputs/CIFAR10_alexnet_scenario_3\n",
            "Num GPUs: 1\n",
            "0\n",
            "Tesla K80\n",
            "True\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Number of training examples: 50000\n",
            "Number of testing examples: 10000\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "trainable parameters: 1728\n",
            "trainable parameters: 64\n",
            "trainable parameters: 110592\n",
            "trainable parameters: 192\n",
            "trainable parameters: 663552\n",
            "trainable parameters: 384\n",
            "trainable parameters: 884736\n",
            "trainable parameters: 256\n",
            "trainable parameters: 589824\n",
            "trainable parameters: 256\n",
            "trainable parameters: 4194304\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 16777216\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 40960\n",
            "trainable parameters: 10\n",
            "The model has 23272266 trainable parameters\n",
            " *************  1250\n",
            "Epoch 0/34\n",
            "----------\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "train Loss: 1.7262 Acc: 0.3382\n",
            "val Loss: 1.3895 Acc: 0.4709\n",
            "\n",
            "Epoch 1/34\n",
            "----------\n",
            "train Loss: 1.3438 Acc: 0.5165\n",
            "val Loss: 1.2926 Acc: 0.5448\n",
            "\n",
            "Epoch 2/34\n",
            "----------\n",
            "train Loss: 1.1716 Acc: 0.5854\n",
            "val Loss: 1.1399 Acc: 0.6002\n",
            "\n",
            "Epoch 3/34\n",
            "----------\n",
            "train Loss: 1.0544 Acc: 0.6329\n",
            "val Loss: 1.0523 Acc: 0.6281\n",
            "\n",
            "Epoch 4/34\n",
            "----------\n",
            "train Loss: 0.9721 Acc: 0.6618\n",
            "val Loss: 1.0479 Acc: 0.6342\n",
            "\n",
            "Epoch 5/34\n",
            "----------\n",
            "train Loss: 0.8930 Acc: 0.6916\n",
            "val Loss: 0.9812 Acc: 0.6592\n",
            "\n",
            "Epoch 6/34\n",
            "----------\n",
            "train Loss: 0.8313 Acc: 0.7113\n",
            "val Loss: 0.9503 Acc: 0.6736\n",
            "\n",
            "Epoch 7/34\n",
            "----------\n",
            "train Loss: 0.6060 Acc: 0.7870\n",
            "val Loss: 0.9023 Acc: 0.7032\n",
            "\n",
            "Epoch 8/34\n",
            "----------\n",
            "train Loss: 0.5342 Acc: 0.8108\n",
            "val Loss: 0.9064 Acc: 0.7069\n",
            "\n",
            "Epoch 9/34\n",
            "----------\n",
            "train Loss: 0.4869 Acc: 0.8273\n",
            "val Loss: 0.9377 Acc: 0.7078\n",
            "\n",
            "Epoch 10/34\n",
            "----------\n",
            "train Loss: 0.4492 Acc: 0.8400\n",
            "val Loss: 0.9632 Acc: 0.7101\n",
            "\n",
            "Epoch 11/34\n",
            "----------\n",
            "train Loss: 0.4123 Acc: 0.8531\n",
            "val Loss: 1.0174 Acc: 0.7075\n",
            "\n",
            "Epoch 12/34\n",
            "----------\n",
            "train Loss: 0.3754 Acc: 0.8669\n",
            "val Loss: 1.0594 Acc: 0.7051\n",
            "\n",
            "Epoch 13/34\n",
            "----------\n",
            "train Loss: 0.3423 Acc: 0.8787\n",
            "val Loss: 1.1267 Acc: 0.7078\n",
            "\n",
            "Epoch 14/34\n",
            "----------\n",
            "train Loss: 0.2945 Acc: 0.8970\n",
            "val Loss: 1.1547 Acc: 0.7092\n",
            "\n",
            "Epoch 15/34\n",
            "----------\n",
            "train Loss: 0.2873 Acc: 0.8993\n",
            "val Loss: 1.1772 Acc: 0.7068\n",
            "\n",
            "Epoch 16/34\n",
            "----------\n",
            "train Loss: 0.2836 Acc: 0.9001\n",
            "val Loss: 1.1941 Acc: 0.7064\n",
            "\n",
            "Epoch 17/34\n",
            "----------\n",
            "train Loss: 0.2754 Acc: 0.9043\n",
            "val Loss: 1.2148 Acc: 0.7078\n",
            "\n",
            "Epoch 18/34\n",
            "----------\n",
            "train Loss: 0.2729 Acc: 0.9041\n",
            "val Loss: 1.2299 Acc: 0.7065\n",
            "\n",
            "Epoch 19/34\n",
            "----------\n",
            "train Loss: 0.2670 Acc: 0.9071\n",
            "val Loss: 1.2472 Acc: 0.7069\n",
            "\n",
            "Epoch 20/34\n",
            "----------\n",
            "train Loss: 0.2650 Acc: 0.9079\n",
            "val Loss: 1.2594 Acc: 0.7067\n",
            "\n",
            "Epoch 21/34\n",
            "----------\n",
            "train Loss: 0.2591 Acc: 0.9091\n",
            "val Loss: 1.2629 Acc: 0.7053\n",
            "\n",
            "Epoch 22/34\n",
            "----------\n",
            "train Loss: 0.2559 Acc: 0.9102\n",
            "val Loss: 1.2657 Acc: 0.7049\n",
            "\n",
            "Epoch 23/34\n",
            "----------\n",
            "train Loss: 0.2581 Acc: 0.9100\n",
            "val Loss: 1.2680 Acc: 0.7051\n",
            "\n",
            "Epoch 24/34\n",
            "----------\n",
            "train Loss: 0.2548 Acc: 0.9105\n",
            "val Loss: 1.2687 Acc: 0.7056\n",
            "\n",
            "Epoch 25/34\n",
            "----------\n",
            "train Loss: 0.2534 Acc: 0.9115\n",
            "val Loss: 1.2708 Acc: 0.7051\n",
            "\n",
            "Epoch 26/34\n",
            "----------\n",
            "train Loss: 0.2574 Acc: 0.9097\n",
            "val Loss: 1.2714 Acc: 0.7054\n",
            "\n",
            "Epoch 27/34\n",
            "----------\n",
            "train Loss: 0.2573 Acc: 0.9096\n",
            "val Loss: 1.2737 Acc: 0.7057\n",
            "\n",
            "Epoch 28/34\n",
            "----------\n",
            "train Loss: 0.2567 Acc: 0.9088\n",
            "val Loss: 1.2738 Acc: 0.7058\n",
            "\n",
            "Epoch 29/34\n",
            "----------\n",
            "train Loss: 0.2570 Acc: 0.9096\n",
            "val Loss: 1.2740 Acc: 0.7060\n",
            "\n",
            "Epoch 30/34\n",
            "----------\n",
            "train Loss: 0.2542 Acc: 0.9109\n",
            "val Loss: 1.2742 Acc: 0.7057\n",
            "\n",
            "Epoch 31/34\n",
            "----------\n",
            "train Loss: 0.2552 Acc: 0.9112\n",
            "val Loss: 1.2743 Acc: 0.7057\n",
            "\n",
            "Epoch 32/34\n",
            "----------\n",
            "train Loss: 0.2546 Acc: 0.9112\n",
            "val Loss: 1.2744 Acc: 0.7055\n",
            "\n",
            "Epoch 33/34\n",
            "----------\n",
            "train Loss: 0.2569 Acc: 0.9094\n",
            "val Loss: 1.2745 Acc: 0.7053\n",
            "\n",
            "Epoch 34/34\n",
            "----------\n",
            "train Loss: 0.2549 Acc: 0.9111\n",
            "val Loss: 1.2748 Acc: 0.7052\n",
            "\n",
            "Training complete in 38m 44s\n",
            "Best val Acc: 0.710100\n",
            "<Figure size 2500x400 with 20 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnXTcf6YIz52",
        "outputId": "f67e652b-e96d-45eb-9449-14c768ed069e"
      },
      "source": [
        "!python /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/TorchClassifier/myTorchEvaluator.py --save_path /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/outputs/ --TAG scenario_3 --model_name alexnet --optimizer Adam --epochs 35"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9.0+cu102\n",
            "Torch Version:  1.9.0+cu102\n",
            "Torchvision Version:  0.10.0+cu102\n",
            "Output path: /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/outputs/CIFAR10_alexnet_scenario_3\n",
            "Num GPUs: 1\n",
            "0\n",
            "Tesla K80\n",
            "True\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Number of training examples: 50000\n",
            "Number of testing examples: 10000\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "trainable parameters: 1728\n",
            "trainable parameters: 64\n",
            "trainable parameters: 110592\n",
            "trainable parameters: 192\n",
            "trainable parameters: 663552\n",
            "trainable parameters: 384\n",
            "trainable parameters: 884736\n",
            "trainable parameters: 256\n",
            "trainable parameters: 589824\n",
            "trainable parameters: 256\n",
            "trainable parameters: 4194304\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 16777216\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 40960\n",
            "trainable parameters: 10\n",
            "The model has 23272266 trainable parameters\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Test Loss: 0.997547\n",
            "\n",
            "Test Accuracy of airplane: 79% (791/1000)\n",
            "Test Accuracy of automobile: 82% (820/1000)\n",
            "Test Accuracy of  bird: 57% (571/1000)\n",
            "Test Accuracy of   cat: 49% (491/1000)\n",
            "Test Accuracy of  deer: 66% (662/1000)\n",
            "Test Accuracy of   dog: 53% (537/1000)\n",
            "Test Accuracy of  frog: 76% (767/1000)\n",
            "Test Accuracy of horse: 75% (756/1000)\n",
            "Test Accuracy of  ship: 81% (818/1000)\n",
            "Test Accuracy of truck: 79% (793/1000)\n",
            "\n",
            "Test Accuracy (Overall): 70% (7006/10000)\n",
            "Test Loss: 0.997 | Test Acc: 70.09%\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yilrIxS1C-no",
        "outputId": "b0b20426-a4aa-4a01-a0b4-9efbe41839ba"
      },
      "source": [
        "!python /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/TorchClassifier/myTorchTrainer.py --TAG scenario_4 --model_name alexnet --optimizer Adam  --epochs 45"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9.0+cu102\n",
            "Torch Version:  1.9.0+cu102\n",
            "Torchvision Version:  0.10.0+cu102\n",
            "Output path: ./outputs/CIFAR10_alexnet_scenario_4\n",
            "Num GPUs: 1\n",
            "0\n",
            "Tesla K80\n",
            "True\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Number of training examples: 50000\n",
            "Number of testing examples: 10000\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "trainable parameters: 1728\n",
            "trainable parameters: 64\n",
            "trainable parameters: 110592\n",
            "trainable parameters: 192\n",
            "trainable parameters: 663552\n",
            "trainable parameters: 384\n",
            "trainable parameters: 884736\n",
            "trainable parameters: 256\n",
            "trainable parameters: 589824\n",
            "trainable parameters: 256\n",
            "trainable parameters: 4194304\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 16777216\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 40960\n",
            "trainable parameters: 10\n",
            "The model has 23272266 trainable parameters\n",
            " *************  1250\n",
            "Epoch 0/44\n",
            "----------\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "train Loss: 1.7487 Acc: 0.3249\n",
            "val Loss: 1.4632 Acc: 0.4580\n",
            "\n",
            "Epoch 1/44\n",
            "----------\n",
            "train Loss: 1.3901 Acc: 0.4964\n",
            "val Loss: 1.2729 Acc: 0.5438\n",
            "\n",
            "Epoch 2/44\n",
            "----------\n",
            "train Loss: 1.2213 Acc: 0.5638\n",
            "val Loss: 1.1839 Acc: 0.5759\n",
            "\n",
            "Epoch 3/44\n",
            "----------\n",
            "train Loss: 1.1087 Acc: 0.6089\n",
            "val Loss: 1.0935 Acc: 0.6067\n",
            "\n",
            "Epoch 4/44\n",
            "----------\n",
            "train Loss: 1.0319 Acc: 0.6399\n",
            "val Loss: 1.0446 Acc: 0.6304\n",
            "\n",
            "Epoch 5/44\n",
            "----------\n",
            "train Loss: 0.9633 Acc: 0.6658\n",
            "val Loss: 1.0430 Acc: 0.6314\n",
            "\n",
            "Epoch 6/44\n",
            "----------\n",
            "train Loss: 0.8977 Acc: 0.6903\n",
            "val Loss: 1.0089 Acc: 0.6625\n",
            "\n",
            "Epoch 7/44\n",
            "----------\n",
            "train Loss: 0.6963 Acc: 0.7538\n",
            "val Loss: 0.9533 Acc: 0.6791\n",
            "\n",
            "Epoch 8/44\n",
            "----------\n",
            "train Loss: 0.6334 Acc: 0.7750\n",
            "val Loss: 0.9591 Acc: 0.6848\n",
            "\n",
            "Epoch 9/44\n",
            "----------\n",
            "train Loss: 0.5899 Acc: 0.7901\n",
            "val Loss: 0.9797 Acc: 0.6887\n",
            "\n",
            "Epoch 10/44\n",
            "----------\n",
            "train Loss: 0.5542 Acc: 0.8014\n",
            "val Loss: 1.0037 Acc: 0.6884\n",
            "\n",
            "Epoch 11/44\n",
            "----------\n",
            "train Loss: 0.5252 Acc: 0.8120\n",
            "val Loss: 1.0308 Acc: 0.6872\n",
            "\n",
            "Epoch 12/44\n",
            "----------\n",
            "train Loss: 0.4930 Acc: 0.8244\n",
            "val Loss: 1.0605 Acc: 0.6891\n",
            "\n",
            "Epoch 13/44\n",
            "----------\n",
            "train Loss: 0.4602 Acc: 0.8368\n",
            "val Loss: 1.1156 Acc: 0.6862\n",
            "\n",
            "Epoch 14/44\n",
            "----------\n",
            "train Loss: 0.4163 Acc: 0.8514\n",
            "val Loss: 1.1315 Acc: 0.6871\n",
            "\n",
            "Epoch 15/44\n",
            "----------\n",
            "train Loss: 0.4076 Acc: 0.8546\n",
            "val Loss: 1.1451 Acc: 0.6859\n",
            "\n",
            "Epoch 16/44\n",
            "----------\n",
            "train Loss: 0.4022 Acc: 0.8576\n",
            "val Loss: 1.1586 Acc: 0.6874\n",
            "\n",
            "Epoch 17/44\n",
            "----------\n",
            "train Loss: 0.3982 Acc: 0.8584\n",
            "val Loss: 1.1721 Acc: 0.6870\n",
            "\n",
            "Epoch 18/44\n",
            "----------\n",
            "train Loss: 0.3905 Acc: 0.8614\n",
            "val Loss: 1.1822 Acc: 0.6887\n",
            "\n",
            "Epoch 19/44\n",
            "----------\n",
            "train Loss: 0.3893 Acc: 0.8618\n",
            "val Loss: 1.1969 Acc: 0.6868\n",
            "\n",
            "Epoch 20/44\n",
            "----------\n",
            "train Loss: 0.3829 Acc: 0.8647\n",
            "val Loss: 1.2070 Acc: 0.6879\n",
            "\n",
            "Epoch 21/44\n",
            "----------\n",
            "train Loss: 0.3778 Acc: 0.8670\n",
            "val Loss: 1.2087 Acc: 0.6869\n",
            "\n",
            "Epoch 22/44\n",
            "----------\n",
            "train Loss: 0.3787 Acc: 0.8665\n",
            "val Loss: 1.2092 Acc: 0.6869\n",
            "\n",
            "Epoch 23/44\n",
            "----------\n",
            "train Loss: 0.3771 Acc: 0.8667\n",
            "val Loss: 1.2096 Acc: 0.6871\n",
            "\n",
            "Epoch 24/44\n",
            "----------\n",
            "train Loss: 0.3756 Acc: 0.8671\n",
            "val Loss: 1.2099 Acc: 0.6861\n",
            "\n",
            "Epoch 25/44\n",
            "----------\n",
            "train Loss: 0.3778 Acc: 0.8646\n",
            "val Loss: 1.2113 Acc: 0.6866\n",
            "\n",
            "Epoch 26/44\n",
            "----------\n",
            "train Loss: 0.3759 Acc: 0.8674\n",
            "val Loss: 1.2124 Acc: 0.6869\n",
            "\n",
            "Epoch 27/44\n",
            "----------\n",
            "train Loss: 0.3772 Acc: 0.8661\n",
            "val Loss: 1.2129 Acc: 0.6863\n",
            "\n",
            "Epoch 28/44\n",
            "----------\n",
            "train Loss: 0.3745 Acc: 0.8683\n",
            "val Loss: 1.2131 Acc: 0.6863\n",
            "\n",
            "Epoch 29/44\n",
            "----------\n",
            "train Loss: 0.3749 Acc: 0.8671\n",
            "val Loss: 1.2132 Acc: 0.6863\n",
            "\n",
            "Epoch 30/44\n",
            "----------\n",
            "train Loss: 0.3781 Acc: 0.8653\n",
            "val Loss: 1.2132 Acc: 0.6863\n",
            "\n",
            "Epoch 31/44\n",
            "----------\n",
            "train Loss: 0.3754 Acc: 0.8668\n",
            "val Loss: 1.2133 Acc: 0.6864\n",
            "\n",
            "Epoch 32/44\n",
            "----------\n",
            "train Loss: 0.3752 Acc: 0.8659\n",
            "val Loss: 1.2134 Acc: 0.6866\n",
            "\n",
            "Epoch 33/44\n",
            "----------\n",
            "train Loss: 0.3754 Acc: 0.8667\n",
            "val Loss: 1.2135 Acc: 0.6866\n",
            "\n",
            "Epoch 34/44\n",
            "----------\n",
            "train Loss: 0.3750 Acc: 0.8663\n",
            "val Loss: 1.2136 Acc: 0.6866\n",
            "\n",
            "Epoch 35/44\n",
            "----------\n",
            "train Loss: 0.3731 Acc: 0.8685\n",
            "val Loss: 1.2136 Acc: 0.6867\n",
            "\n",
            "Epoch 36/44\n",
            "----------\n",
            "train Loss: 0.3761 Acc: 0.8660\n",
            "val Loss: 1.2136 Acc: 0.6867\n",
            "\n",
            "Epoch 37/44\n",
            "----------\n",
            "train Loss: 0.3751 Acc: 0.8660\n",
            "val Loss: 1.2136 Acc: 0.6868\n",
            "\n",
            "Epoch 38/44\n",
            "----------\n",
            "train Loss: 0.3754 Acc: 0.8675\n",
            "val Loss: 1.2136 Acc: 0.6867\n",
            "\n",
            "Epoch 39/44\n",
            "----------\n",
            "train Loss: 0.3748 Acc: 0.8663\n",
            "val Loss: 1.2136 Acc: 0.6867\n",
            "\n",
            "Epoch 40/44\n",
            "----------\n",
            "train Loss: 0.3761 Acc: 0.8666\n",
            "val Loss: 1.2136 Acc: 0.6867\n",
            "\n",
            "Epoch 41/44\n",
            "----------\n",
            "train Loss: 0.3751 Acc: 0.8683\n",
            "val Loss: 1.2136 Acc: 0.6867\n",
            "\n",
            "Epoch 42/44\n",
            "----------\n",
            "train Loss: 0.3755 Acc: 0.8678\n",
            "val Loss: 1.2136 Acc: 0.6867\n",
            "\n",
            "Epoch 43/44\n",
            "----------\n",
            "train Loss: 0.3765 Acc: 0.8669\n",
            "val Loss: 1.2136 Acc: 0.6867\n",
            "\n",
            "Epoch 44/44\n",
            "----------\n",
            "train Loss: 0.3747 Acc: 0.8674\n",
            "val Loss: 1.2136 Acc: 0.6867\n",
            "\n",
            "Training complete in 49m 58s\n",
            "Best val Acc: 0.689100\n",
            "<Figure size 2500x400 with 20 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jX1U3LPTD8w",
        "outputId": "bdc140e7-e834-496b-b719-c0e56571b7af"
      },
      "source": [
        "!python /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/TorchClassifier/myTorchEvaluator.py --save_path /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/outputs/ --TAG scenario_4 --model_name alexnet --optimizer Adam  --epochs 45 "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9.0+cu102\n",
            "Torch Version:  1.9.0+cu102\n",
            "Torchvision Version:  0.10.0+cu102\n",
            "Output path: /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/outputs/CIFAR10_alexnet_scenario_4\n",
            "Num GPUs: 1\n",
            "0\n",
            "Tesla K80\n",
            "True\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Number of training examples: 50000\n",
            "Number of testing examples: 10000\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "trainable parameters: 1728\n",
            "trainable parameters: 64\n",
            "trainable parameters: 110592\n",
            "trainable parameters: 192\n",
            "trainable parameters: 663552\n",
            "trainable parameters: 384\n",
            "trainable parameters: 884736\n",
            "trainable parameters: 256\n",
            "trainable parameters: 589824\n",
            "trainable parameters: 256\n",
            "trainable parameters: 4194304\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 16777216\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 40960\n",
            "trainable parameters: 10\n",
            "The model has 23272266 trainable parameters\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Test Loss: 1.053561\n",
            "\n",
            "Test Accuracy of airplane: 76% (760/1000)\n",
            "Test Accuracy of automobile: 82% (825/1000)\n",
            "Test Accuracy of  bird: 55% (552/1000)\n",
            "Test Accuracy of   cat: 46% (465/1000)\n",
            "Test Accuracy of  deer: 61% (618/1000)\n",
            "Test Accuracy of   dog: 59% (592/1000)\n",
            "Test Accuracy of  frog: 76% (767/1000)\n",
            "Test Accuracy of horse: 75% (759/1000)\n",
            "Test Accuracy of  ship: 78% (783/1000)\n",
            "Test Accuracy of truck: 77% (774/1000)\n",
            "\n",
            "Test Accuracy (Overall): 68% (6895/10000)\n",
            "Test Loss: 1.053 | Test Acc: 68.95%\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WEiteeoVUSl",
        "outputId": "4ffb3f8f-9db2-47fb-b1cb-a3edde5726ea"
      },
      "source": [
        "!python /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/TorchClassifier/myTorchTrainer.py --TAG scenario_5 --model_name alexnet --optimizer SGD  --epochs 25"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9.0+cu102\n",
            "Torch Version:  1.9.0+cu102\n",
            "Torchvision Version:  0.10.0+cu102\n",
            "Output path: ./outputs/CIFAR10_alexnet_scenario_5\n",
            "Num GPUs: 1\n",
            "0\n",
            "Tesla K80\n",
            "True\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Number of training examples: 50000\n",
            "Number of testing examples: 10000\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "trainable parameters: 1728\n",
            "trainable parameters: 64\n",
            "trainable parameters: 110592\n",
            "trainable parameters: 192\n",
            "trainable parameters: 663552\n",
            "trainable parameters: 384\n",
            "trainable parameters: 884736\n",
            "trainable parameters: 256\n",
            "trainable parameters: 589824\n",
            "trainable parameters: 256\n",
            "trainable parameters: 4194304\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 16777216\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 40960\n",
            "trainable parameters: 10\n",
            "The model has 23272266 trainable parameters\n",
            " *************  1250\n",
            "Epoch 0/24\n",
            "----------\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "train Loss: 2.0481 Acc: 0.1996\n",
            "val Loss: 1.6720 Acc: 0.3441\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 1.5265 Acc: 0.4232\n",
            "val Loss: 1.4449 Acc: 0.4616\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 1.2335 Acc: 0.5551\n",
            "val Loss: 1.1061 Acc: 0.6002\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 1.0312 Acc: 0.6317\n",
            "val Loss: 1.0329 Acc: 0.6331\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.8781 Acc: 0.6902\n",
            "val Loss: 1.0251 Acc: 0.6410\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.7477 Acc: 0.7389\n",
            "val Loss: 0.9296 Acc: 0.6904\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.6381 Acc: 0.7781\n",
            "val Loss: 0.9503 Acc: 0.6875\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.3451 Acc: 0.8824\n",
            "val Loss: 0.7862 Acc: 0.7566\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.2628 Acc: 0.9108\n",
            "val Loss: 0.8440 Acc: 0.7510\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.2095 Acc: 0.9304\n",
            "val Loss: 0.8822 Acc: 0.7570\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.1636 Acc: 0.9476\n",
            "val Loss: 0.9710 Acc: 0.7574\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.1254 Acc: 0.9608\n",
            "val Loss: 1.0511 Acc: 0.7534\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.0948 Acc: 0.9722\n",
            "val Loss: 1.1094 Acc: 0.7524\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.0683 Acc: 0.9806\n",
            "val Loss: 1.2252 Acc: 0.7518\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.0443 Acc: 0.9898\n",
            "val Loss: 1.2319 Acc: 0.7527\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.0395 Acc: 0.9921\n",
            "val Loss: 1.2515 Acc: 0.7539\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.0376 Acc: 0.9917\n",
            "val Loss: 1.2684 Acc: 0.7532\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.0361 Acc: 0.9928\n",
            "val Loss: 1.2790 Acc: 0.7514\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.0344 Acc: 0.9925\n",
            "val Loss: 1.2930 Acc: 0.7524\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.0329 Acc: 0.9937\n",
            "val Loss: 1.3066 Acc: 0.7528\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.0321 Acc: 0.9933\n",
            "val Loss: 1.3177 Acc: 0.7527\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.0298 Acc: 0.9942\n",
            "val Loss: 1.3201 Acc: 0.7526\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.0305 Acc: 0.9940\n",
            "val Loss: 1.3219 Acc: 0.7518\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.0301 Acc: 0.9940\n",
            "val Loss: 1.3227 Acc: 0.7517\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.0292 Acc: 0.9940\n",
            "val Loss: 1.3237 Acc: 0.7519\n",
            "\n",
            "Training complete in 23m 30s\n",
            "Best val Acc: 0.757400\n",
            "<Figure size 2500x400 with 20 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1000x1000 with 1 Axes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIXJ8Z99b2BA",
        "outputId": "972ef044-a0d3-4d7c-8a56-53619d352ba2"
      },
      "source": [
        "!python /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/TorchClassifier/myTorchEvaluator.py --save_path /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/outputs/  --TAG scenario_5 --model_name alexnet --optimizer SGD  --epochs 25"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9.0+cu102\n",
            "Torch Version:  1.9.0+cu102\n",
            "Torchvision Version:  0.10.0+cu102\n",
            "Output path: /content/drive/MyDrive/ColabNotebooks/MultiModalClassifier/outputs/CIFAR10_alexnet_scenario_5\n",
            "Num GPUs: 1\n",
            "0\n",
            "Tesla K80\n",
            "True\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Number of training examples: 50000\n",
            "Number of testing examples: 10000\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "trainable parameters: 1728\n",
            "trainable parameters: 64\n",
            "trainable parameters: 110592\n",
            "trainable parameters: 192\n",
            "trainable parameters: 663552\n",
            "trainable parameters: 384\n",
            "trainable parameters: 884736\n",
            "trainable parameters: 256\n",
            "trainable parameters: 589824\n",
            "trainable parameters: 256\n",
            "trainable parameters: 4194304\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 16777216\n",
            "trainable parameters: 4096\n",
            "trainable parameters: 40960\n",
            "trainable parameters: 10\n",
            "The model has 23272266 trainable parameters\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Test Loss: 1.004619\n",
            "\n",
            "Test Accuracy of airplane: 78% (782/1000)\n",
            "Test Accuracy of automobile: 85% (853/1000)\n",
            "Test Accuracy of  bird: 69% (698/1000)\n",
            "Test Accuracy of   cat: 55% (556/1000)\n",
            "Test Accuracy of  deer: 72% (727/1000)\n",
            "Test Accuracy of   dog: 59% (592/1000)\n",
            "Test Accuracy of  frog: 81% (819/1000)\n",
            "Test Accuracy of horse: 77% (779/1000)\n",
            "Test Accuracy of  ship: 87% (872/1000)\n",
            "Test Accuracy of truck: 81% (810/1000)\n",
            "\n",
            "Test Accuracy (Overall): 74% (7488/10000)\n",
            "Test Loss: 1.004 | Test Acc: 74.88%\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        }
      ]
    }
  ]
}